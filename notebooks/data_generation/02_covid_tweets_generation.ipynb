{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8936757d",
   "metadata": {},
   "source": [
    "# COVID Tweet Synthetic Data Generation\n",
    "\n",
    "This notebook focuses on generating synthetic fake tweets from real COVID-related tweets.\n",
    "The process is similar to news articles but adapted for the shorter, more informal format of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d1a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Import custom modules\n",
    "from src.data_generation.llm_client import create_llm_client, SyntheticDataResult\n",
    "from src.utils.data_utils import load_config, load_raw_data, save_processed_data\n",
    "from src.utils.text_preprocessing import TextPreprocessor\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c830aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and environment\n",
    "config = load_config()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Configuration and environment loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c87d4",
   "metadata": {},
   "source": [
    "## Load COVID Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COVID tweets data\n",
    "try:\n",
    "    tweets_df = load_raw_data(\"tweets\")\n",
    "    print(f\"Loaded {len(tweets_df)} tweets\")\n",
    "    \n",
    "    if len(tweets_df) > 0:\n",
    "        print(\"\\nDataset info:\")\n",
    "        print(tweets_df.info())\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(tweets_df.head())\n",
    "    else:\n",
    "        print(\"No tweet data found. Creating sample data for demonstration...\")\n",
    "        \n",
    "        # Create sample COVID tweets\n",
    "        sample_tweets = [\n",
    "            {\n",
    "                'text': 'Breaking: New COVID variant found in 500 cases across London. Scientists say its 80% more contagious than Delta. Hospitals preparing for surge. #COVID19 #Health',\n",
    "                'user': 'health_reporter',\n",
    "                'date': '2024-01-15',\n",
    "                'retweets': 1250,\n",
    "                'likes': 3400\n",
    "            },\n",
    "            {\n",
    "                'text': 'Just got my 4th COVID shot! Studies show 96% protection rate. Feel great and ready for winter season. Everyone should get vaccinated! üíâ #VaccinesWork',\n",
    "                'user': 'medical_student',\n",
    "                'date': '2024-01-12',\n",
    "                'retweets': 89,\n",
    "                'likes': 456\n",
    "            },\n",
    "            {\n",
    "                'text': 'COVID deaths down 60% this month in our county. Mask mandate lifted yesterday. Local ICU capacity back to normal levels. Great news! üò∑‚û°Ô∏èüòä',\n",
    "                'user': 'county_health',\n",
    "                'date': '2024-01-10',\n",
    "                'retweets': 567,\n",
    "                'likes': 1890\n",
    "            },\n",
    "            {\n",
    "                'text': 'My grandmother, 85, recovered from COVID in just 5 days with new treatment. Doctors said its 90% effective for elderly patients. Amazing progress! ‚ù§Ô∏è',\n",
    "                'user': 'grateful_family',\n",
    "                'date': '2024-01-08',\n",
    "                'retweets': 234,\n",
    "                'likes': 892\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        tweets_df = pd.DataFrame(sample_tweets)\n",
    "        print(f\"Created sample dataset with {len(tweets_df)} tweets for demonstration.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    tweets_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c5535",
   "metadata": {},
   "source": [
    "## Tweet-Specific Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56281956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet_text(text):\n",
    "    \"\"\"Clean tweet text while preserving hashtags and mentions for context.\"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Clean extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_tweet_facts(llm_client, tweet_text, num_facts=2):\n",
    "    \"\"\"Extract facts from tweets with tweet-specific prompt.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Extract exactly {num_facts} key factual claims from this COVID-related tweet. \n",
    "    Focus on specific, verifiable facts (numbers, percentages, locations, medical claims, etc.).\n",
    "    Ignore opinions, emotions, and general statements. Return only the facts as a numbered list.\n",
    "    \n",
    "    Tweet: {tweet_text}\n",
    "    \n",
    "    Facts:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm_client.client.chat.completions.create(\n",
    "            model=llm_client.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=llm_client.temperature,\n",
    "            max_tokens=llm_client.max_tokens\n",
    "        )\n",
    "        \n",
    "        facts_text = response.choices[0].message.content.strip()\n",
    "        facts = llm_client._parse_facts_from_response(facts_text)\n",
    "        \n",
    "        return facts[:num_facts]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting facts from tweet: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_synthetic_tweet(llm_client, original_tweet, modified_facts):\n",
    "    \"\"\"Generate synthetic tweet with modified facts.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Rewrite this COVID-related tweet to incorporate the modified facts while maintaining:\n",
    "    - Tweet-like language and tone\n",
    "    - Similar length (under 280 characters)\n",
    "    - Hashtags and emojis where appropriate\n",
    "    - Believable but false information\n",
    "    \n",
    "    Original tweet: {original_tweet}\n",
    "    \n",
    "    Modified facts to incorporate:\n",
    "    {chr(10).join([f\"- {fact}\" for fact in modified_facts])}\n",
    "    \n",
    "    Rewritten tweet:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm_client.client.chat.completions.create(\n",
    "            model=llm_client.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=llm_client.temperature,\n",
    "            max_tokens=llm_client.max_tokens\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating synthetic tweet: {e}\")\n",
    "        return original_tweet\n",
    "\n",
    "print(\"Tweet processing functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d03377",
   "metadata": {},
   "source": [
    "## Initialize LLM Client and Process Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM client\n",
    "llm_provider = \"openai\"\n",
    "\n",
    "try:\n",
    "    llm_client = create_llm_client(\n",
    "        provider=llm_provider,\n",
    "        model_name=config['llm'][llm_provider]['model'],\n",
    "        temperature=config['llm'][llm_provider]['temperature'],\n",
    "        max_tokens=config['llm'][llm_provider]['max_tokens']\n",
    "    )\n",
    "    print(f\"Successfully initialized {llm_provider} client for tweets\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing LLM client: {e}\")\n",
    "    llm_client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec58dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tweets to generate synthetic versions\n",
    "if llm_client is not None and len(tweets_df) > 0:\n",
    "    \n",
    "    synthetic_tweet_results = []\n",
    "    facts_per_tweet = 2  # Usually fewer facts per tweet due to length\n",
    "    \n",
    "    # Process all sample tweets\n",
    "    sample_size = len(tweets_df)\n",
    "    \n",
    "    print(f\"Processing {sample_size} tweets...\")\n",
    "    \n",
    "    for idx, row in tqdm(tweets_df.iterrows(), total=sample_size):\n",
    "        tweet_text = clean_tweet_text(row['text'])\n",
    "        \n",
    "        print(f\"\\nProcessing tweet {idx + 1}: {tweet_text[:50]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Extract facts from tweet\n",
    "            original_facts = extract_tweet_facts(llm_client, tweet_text, facts_per_tweet)\n",
    "            \n",
    "            if not original_facts:\n",
    "                print(f\"  ‚ö†Ô∏è No facts extracted, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  ‚úì Extracted {len(original_facts)} facts\")\n",
    "            \n",
    "            # Step 2: Modify facts\n",
    "            modified_facts = llm_client.modify_facts(original_facts)\n",
    "            print(f\"  ‚úì Modified facts\")\n",
    "            \n",
    "            # Step 3: Generate synthetic tweet\n",
    "            synthetic_tweet = generate_synthetic_tweet(llm_client, tweet_text, modified_facts)\n",
    "            print(f\"  ‚úì Generated synthetic tweet\")\n",
    "            \n",
    "            # Store result\n",
    "            result = SyntheticDataResult(\n",
    "                original_text=tweet_text,\n",
    "                original_facts=original_facts,\n",
    "                modified_facts=modified_facts,\n",
    "                synthetic_text=synthetic_tweet,\n",
    "                generation_metadata={\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'model': llm_client.model_name,\n",
    "                    'provider': llm_provider,\n",
    "                    'type': 'tweet',\n",
    "                    'original_user': row.get('user', 'unknown'),\n",
    "                    'original_engagement': {\n",
    "                        'retweets': row.get('retweets', 0),\n",
    "                        'likes': row.get('likes', 0)\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            synthetic_tweet_results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error processing tweet: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nCompleted processing. Generated {len(synthetic_tweet_results)} synthetic tweets.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping synthetic tweet generation due to missing LLM client or data.\")\n",
    "    synthetic_tweet_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3ece9",
   "metadata": {},
   "source": [
    "## Results Display and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display synthetic tweet results\n",
    "if synthetic_tweet_results:\n",
    "    print(\"SYNTHETIC TWEET GENERATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(synthetic_tweet_results):\n",
    "        print(f\"\\nüê¶ TWEET PAIR {i + 1}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(\"\\nüì± ORIGINAL TWEET:\")\n",
    "        print(f\"  {result.original_text}\")\n",
    "        print(f\"  [Length: {len(result.original_text)} chars]\")\n",
    "        \n",
    "        print(\"\\nüîç EXTRACTED FACTS:\")\n",
    "        for j, fact in enumerate(result.original_facts, 1):\n",
    "            print(f\"  {j}. {fact}\")\n",
    "        \n",
    "        print(\"\\nüîÑ MODIFIED FACTS:\")\n",
    "        for j, fact in enumerate(result.modified_facts, 1):\n",
    "            print(f\"  {j}. {fact}\")\n",
    "        \n",
    "        print(\"\\nü§ñ SYNTHETIC TWEET:\")\n",
    "        print(f\"  {result.synthetic_text}\")\n",
    "        print(f\"  [Length: {len(result.synthetic_text)} chars]\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "else:\n",
    "    print(\"No synthetic tweet results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tweet characteristics\n",
    "if synthetic_tweet_results:\n",
    "    # Create analysis DataFrame\n",
    "    tweet_analysis = []\n",
    "    \n",
    "    for result in synthetic_tweet_results:\n",
    "        original_hashtags = len(re.findall(r'#\\w+', result.original_text))\n",
    "        synthetic_hashtags = len(re.findall(r'#\\w+', result.synthetic_text))\n",
    "        \n",
    "        original_mentions = len(re.findall(r'@\\w+', result.original_text))\n",
    "        synthetic_mentions = len(re.findall(r'@\\w+', result.synthetic_text))\n",
    "        \n",
    "        original_emojis = len(re.findall(r'[üòÄ-üôøüåÄ-üóøüöÄ-üõøüáÄ-üáø]', result.original_text))\n",
    "        synthetic_emojis = len(re.findall(r'[üòÄ-üôøüåÄ-üóøüöÄ-üõøüáÄ-üáø]', result.synthetic_text))\n",
    "        \n",
    "        tweet_analysis.append({\n",
    "            'original_length': len(result.original_text),\n",
    "            'synthetic_length': len(result.synthetic_text),\n",
    "            'original_words': len(result.original_text.split()),\n",
    "            'synthetic_words': len(result.synthetic_text.split()),\n",
    "            'original_hashtags': original_hashtags,\n",
    "            'synthetic_hashtags': synthetic_hashtags,\n",
    "            'original_mentions': original_mentions,\n",
    "            'synthetic_mentions': synthetic_mentions,\n",
    "            'original_emojis': original_emojis,\n",
    "            'synthetic_emojis': synthetic_emojis,\n",
    "            'facts_count': len(result.original_facts)\n",
    "        })\n",
    "    \n",
    "    analysis_df = pd.DataFrame(tweet_analysis)\n",
    "    \n",
    "    print(\"TWEET ANALYSIS STATISTICS\")\n",
    "    print(\"=\" * 30)\n",
    "    print(analysis_df.describe())\n",
    "    \n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Synthetic Tweet Analysis', fontsize=16)\n",
    "    \n",
    "    # Length comparison\n",
    "    axes[0, 0].scatter(analysis_df['original_length'], analysis_df['synthetic_length'])\n",
    "    axes[0, 0].plot([0, 280], [0, 280], 'r--', alpha=0.5)  # Twitter character limit line\n",
    "    axes[0, 0].axhline(y=280, color='r', linestyle=':', alpha=0.5, label='Twitter limit')\n",
    "    axes[0, 0].axvline(x=280, color='r', linestyle=':', alpha=0.5)\n",
    "    axes[0, 0].set_xlabel('Original Tweet Length')\n",
    "    axes[0, 0].set_ylabel('Synthetic Tweet Length')\n",
    "    axes[0, 0].set_title('Character Count Comparison')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Word count comparison\n",
    "    axes[0, 1].scatter(analysis_df['original_words'], analysis_df['synthetic_words'])\n",
    "    axes[0, 1].plot([0, analysis_df['original_words'].max()], [0, analysis_df['original_words'].max()], 'r--', alpha=0.5)\n",
    "    axes[0, 1].set_xlabel('Original Word Count')\n",
    "    axes[0, 1].set_ylabel('Synthetic Word Count')\n",
    "    axes[0, 1].set_title('Word Count Comparison')\n",
    "    \n",
    "    # Hashtag preservation\n",
    "    axes[0, 2].scatter(analysis_df['original_hashtags'], analysis_df['synthetic_hashtags'])\n",
    "    axes[0, 2].plot([0, analysis_df['original_hashtags'].max()], [0, analysis_df['original_hashtags'].max()], 'r--', alpha=0.5)\n",
    "    axes[0, 2].set_xlabel('Original Hashtags')\n",
    "    axes[0, 2].set_ylabel('Synthetic Hashtags')\n",
    "    axes[0, 2].set_title('Hashtag Preservation')\n",
    "    \n",
    "    # Length distribution\n",
    "    axes[1, 0].hist([analysis_df['original_length'], analysis_df['synthetic_length']], \n",
    "                   bins=10, alpha=0.7, label=['Original', 'Synthetic'], edgecolor='black')\n",
    "    axes[1, 0].axvline(x=280, color='r', linestyle='--', alpha=0.5, label='Twitter limit')\n",
    "    axes[1, 0].set_xlabel('Character Count')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Length Distribution')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Facts extracted\n",
    "    axes[1, 1].hist(analysis_df['facts_count'], bins=5, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 1].set_xlabel('Number of Facts Extracted')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Facts per Tweet')\n",
    "    \n",
    "    # Emoji preservation\n",
    "    axes[1, 2].scatter(analysis_df['original_emojis'], analysis_df['synthetic_emojis'])\n",
    "    axes[1, 2].plot([0, analysis_df['original_emojis'].max()], [0, analysis_df['original_emojis'].max()], 'r--', alpha=0.5)\n",
    "    axes[1, 2].set_xlabel('Original Emojis')\n",
    "    axes[1, 2].set_ylabel('Synthetic Emojis')\n",
    "    axes[1, 2].set_title('Emoji Preservation')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No tweet data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa223fc",
   "metadata": {},
   "source": [
    "## Save Synthetic Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic tweet data\n",
    "if synthetic_tweet_results:\n",
    "    # Create dataset with original and synthetic tweet pairs\n",
    "    synthetic_tweet_dataset = []\n",
    "    \n",
    "    for result in synthetic_tweet_results:\n",
    "        # Add original (real) tweet\n",
    "        synthetic_tweet_dataset.append({\n",
    "            'text': result.original_text,\n",
    "            'label': 'real',\n",
    "            'type': 'original_tweet',\n",
    "            'facts': '|'.join(result.original_facts),\n",
    "            'character_count': len(result.original_text),\n",
    "            'word_count': len(result.original_text.split()),\n",
    "            'hashtag_count': len(re.findall(r'#\\w+', result.original_text)),\n",
    "            'mention_count': len(re.findall(r'@\\w+', result.original_text)),\n",
    "            'generation_metadata': None\n",
    "        })\n",
    "        \n",
    "        # Add synthetic (fake) tweet\n",
    "        synthetic_tweet_dataset.append({\n",
    "            'text': result.synthetic_text,\n",
    "            'label': 'fake',\n",
    "            'type': 'synthetic_tweet',\n",
    "            'facts': '|'.join(result.modified_facts),\n",
    "            'character_count': len(result.synthetic_text),\n",
    "            'word_count': len(result.synthetic_text.split()),\n",
    "            'hashtag_count': len(re.findall(r'#\\w+', result.synthetic_text)),\n",
    "            'mention_count': len(re.findall(r'@\\w+', result.synthetic_text)),\n",
    "            'generation_metadata': json.dumps(result.generation_metadata)\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame and save\n",
    "    synthetic_tweets_df = pd.DataFrame(synthetic_tweet_dataset)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"synthetic_covid_tweets_{timestamp}.csv\"\n",
    "    \n",
    "    save_processed_data(synthetic_tweets_df, filename, \"synthetic\")\n",
    "    \n",
    "    print(f\"Saved {len(synthetic_tweets_df)} tweet records to data/synthetic/{filename}\")\n",
    "    print(f\"\\nDataset breakdown:\")\n",
    "    print(synthetic_tweets_df['label'].value_counts())\n",
    "    print(f\"\\nCharacter count statistics:\")\n",
    "    print(synthetic_tweets_df.groupby('label')['character_count'].describe())\n",
    "    \n",
    "    # Save detailed results\n",
    "    detailed_tweet_results = []\n",
    "    for result in synthetic_tweet_results:\n",
    "        detailed_tweet_results.append({\n",
    "            'original_text': result.original_text,\n",
    "            'original_facts': result.original_facts,\n",
    "            'modified_facts': result.modified_facts,\n",
    "            'synthetic_text': result.synthetic_text,\n",
    "            'metadata': result.generation_metadata\n",
    "        })\n",
    "    \n",
    "    json_filename = f\"detailed_tweet_generation_results_{timestamp}.json\"\n",
    "    json_path = f\"data/synthetic/{json_filename}\"\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(detailed_tweet_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved detailed tweet results to {json_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No synthetic tweet data to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e36bc",
   "metadata": {},
   "source": [
    "## Tweet-Specific Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88deef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tweet-specific quality metrics\n",
    "if synthetic_tweet_results:\n",
    "    print(\"TWEET QUALITY ASSESSMENT\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    quality_metrics = []\n",
    "    \n",
    "    for i, result in enumerate(synthetic_tweet_results):\n",
    "        original = result.original_text\n",
    "        synthetic = result.synthetic_text\n",
    "        \n",
    "        # Length compliance (under Twitter's 280 character limit)\n",
    "        length_compliant = len(synthetic) <= 280\n",
    "        \n",
    "        # Style preservation (hashtags, emojis, mentions)\n",
    "        has_hashtags = '#' in synthetic if '#' in original else True\n",
    "        has_emojis = bool(re.search(r'[üòÄ-üôøüåÄ-üóøüöÄ-üõøüáÄ-üáø]', synthetic)) if bool(re.search(r'[üòÄ-üôøüåÄ-üóøüöÄ-üõøüáÄ-üáø]', original)) else True\n",
    "        \n",
    "        # Length similarity (not too different from original)\n",
    "        length_ratio = len(synthetic) / len(original) if len(original) > 0 else 1\n",
    "        length_similar = 0.5 <= length_ratio <= 2.0\n",
    "        \n",
    "        quality_score = sum([\n",
    "            length_compliant,\n",
    "            has_hashtags,\n",
    "            has_emojis,\n",
    "            length_similar\n",
    "        ]) / 4\n",
    "        \n",
    "        quality_metrics.append({\n",
    "            'tweet_id': i + 1,\n",
    "            'length_compliant': length_compliant,\n",
    "            'has_hashtags': has_hashtags,\n",
    "            'has_emojis': has_emojis,\n",
    "            'length_similar': length_similar,\n",
    "            'quality_score': quality_score,\n",
    "            'original_length': len(original),\n",
    "            'synthetic_length': len(synthetic),\n",
    "            'length_ratio': length_ratio\n",
    "        })\n",
    "    \n",
    "    quality_df = pd.DataFrame(quality_metrics)\n",
    "    \n",
    "    print(f\"Average Quality Score: {quality_df['quality_score'].mean():.2f}\")\n",
    "    print(f\"Length Compliance: {quality_df['length_compliant'].mean()*100:.1f}%\")\n",
    "    print(f\"Style Preservation (hashtags): {quality_df['has_hashtags'].mean()*100:.1f}%\")\n",
    "    print(f\"Style Preservation (emojis): {quality_df['has_emojis'].mean()*100:.1f}%\")\n",
    "    print(f\"Length Similarity: {quality_df['length_similar'].mean()*100:.1f}%\")\n",
    "    \n",
    "    # Visualize quality metrics\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    quality_scores = quality_df['quality_score']\n",
    "    plt.hist(quality_scores, bins=10, alpha=0.7, edgecolor='black')\n",
    "    plt.axvline(quality_scores.mean(), color='red', linestyle='--', label=f'Mean: {quality_scores.mean():.2f}')\n",
    "    plt.xlabel('Quality Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Quality Score Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    metrics_summary = [\n",
    "        quality_df['length_compliant'].mean(),\n",
    "        quality_df['has_hashtags'].mean(),\n",
    "        quality_df['has_emojis'].mean(),\n",
    "        quality_df['length_similar'].mean()\n",
    "    ]\n",
    "    metric_names = ['Length\\nCompliant', 'Has\\nHashtags', 'Has\\nEmojis', 'Length\\nSimilar']\n",
    "    \n",
    "    bars = plt.bar(metric_names, metrics_summary, alpha=0.7)\n",
    "    plt.ylabel('Success Rate')\n",
    "    plt.title('Quality Metrics Breakdown')\n",
    "    plt.ylim(0, 1.1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, metrics_summary):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.scatter(quality_df['original_length'], quality_df['synthetic_length'])\n",
    "    plt.plot([0, 280], [0, 280], 'r--', alpha=0.5)\n",
    "    plt.axhline(y=280, color='r', linestyle=':', alpha=0.5, label='Twitter limit')\n",
    "    plt.axvline(x=280, color='r', linestyle=':', alpha=0.5)\n",
    "    plt.xlabel('Original Length')\n",
    "    plt.ylabel('Synthetic Length')\n",
    "    plt.title('Length Preservation')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No tweet data available for quality assessment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45413d4",
   "metadata": {},
   "source": [
    "## Next Steps for Tweet Processing\n",
    "\n",
    "1. **Scale up**: Process larger Twitter datasets\n",
    "2. **User behavior**: Consider user characteristics and engagement patterns\n",
    "3. **Temporal aspects**: Account for trending topics and time-sensitive information\n",
    "4. **Thread handling**: Process tweet threads and conversations\n",
    "5. **Multi-modal content**: Handle tweets with images, videos, links\n",
    "6. **Network effects**: Consider retweet and mention patterns\n",
    "\n",
    "The synthetic tweet data can now be combined with news article data for comprehensive fake news detection model training."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
